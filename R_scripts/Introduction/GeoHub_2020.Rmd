---
title: "Opengeohub summer school 2020: Global air pollution modeling."
author: "Meng Lu, Utrecht University"
date: "June, 2020"
output:
  html_document:
    fig_height: 8
    fig_width: 12
---

### outline  
1. Data: dataset, preprocessing, visualisation,
2. priminarly examination: paired correlation and spatial correlation, scatterplot
3. machine learning methods: model parameter tunning, interpretation


```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.width=12, fig.height=8, fig.path = 'Figs_geohub/',
                      echo=T, include = T, warning = FALSE, message = FALSE)

```
 
##### This tutorial shows from data exploration to the modelling process for the global air pollution modelling project. The statistical learning methods used include Lasso, random forest, stochastic gradient boosting, extreme gradient boosting. The partial dependence plot and variable importance are visualised to partly interpretate models.   

Required packages

```{r, include=T}
ipak <- function(pkg){
   new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
   if (length(new.pkg)) 
    install.packages(new.pkg, dependencies = TRUE)
  sapply(pkg, require, character.only = TRUE)
}
#repos='http://cran.muenster.r-project.org'

stdata = c("sp", "sf", "raster")
Stat_methods = c("lme4", "glmnet", "ranger", "gbm", "xgboost", "party", "caret", "gstat")
visual = c("RColorBrewer", "ggplot2", "corrplot", "tmap", "leaflet", "mapview","leafem", "pdp", "vip", "DT", "sparkline")
map = c("maptools")
tidy = c("devtools", "dplyr",  "tidyr", "reshape2", "knitr")
other = c("countrycode", "htmlwidgets", "data.table", "Matrix", "GGally")
 
packages <- c(stdata, tidy, Stat_methods, visual, map, other)
ipak(packages)
```


[APMtools](https://github.com/mengluchu/APMtools) is an R package providing datasets for global air pollution modelling and tools to streamline and facilitate air pollution mapping using statistical methods. Please have a [read](https://github.com/mengluchu/APMtools) of it on Github.

```{r}
install_github("mengluchu/APMtools")
library(APMtools)
ls("package:APMtools")
```

Load data: 

```{r}
#gd = fread("~/Documents/GitHub/Global mapping/2020_06_world/stations_20200602.csv")
#avg = fread("~/Documents/GitHub/Global mapping/oaqEUAUCAUS.csv")
#gdata = merge(gd, avg, by.x = c("long", "lat"), by.y = c("LONGITUDE","LATITUDE" ))
#g1 = na_if(gdata, -9999.9)
#g2 = g1%>%dplyr::select(-id, -dir, -V1)%>%filter(value_mean >0)  
data("global_annual")  
```
 
Predictor variables:

```{r}
vastring = "road|nightlight|population|temp|wind|trop|indu|elev"
```
 
Dataset:

* value_mean: annual mean $NO_2$ ($mg/m^3$). 
(
for the dataset merged.rda:
* day_value: annual mean $NO_2$ ($mg/m^3$) at daytime. 
* night_value: annual mean $NO_2$ ($mg/m^3$) at night time.   
)

*1*. road_class_XX_size: road lenght within a buffer with radius "size" of type XX. ROAD_1: highway, ROAD_2: primary, ROAD_3: secondary, ROAD_4: tertiary, ROAD_5: unpaved   
*2*. industry_size: Industrial area within a buffer with radius "size".   
*3*. trop_mean: TROPOMI averaged over Feb 2018 - Jan 2019.    
*4*. temperature_2m_m: monthly mean temperature at 2m height of month "m".  
*5*. wind_speed_10m_m:monthly mean wind speed at 2m height of month "m".  
*6*. poppulation_1000/ 3000 /5000: population 1, 3, 5 km resolution.  
*7*. Rsp: Surface remote sensing and chemical transport model product (only for 2012).  
*8*. OMI_mean_filt: OMI column density, 2017 annual average.    
*9*. nightlight_size: nightlight VIIRS data in original resolution (500 m) and various buffer sizes. 

NO2 annual concentration, all the units are converted to ug/m3 (micro per cubic meter). In the data display later you can see countries with different units. 

```{r}
global_annual %>% dplyr::select(value_mean ) %>% summary()
#datatable(g2, rownames = FALSE, filter = "top", options = list(pageLength = 5, scrollX = T))
```


Merge roads of different road types, here 3, 4, 5, the road length of these road types are aggregated. The original road types are substituted (with keep = T, they are remained). 
 
```{r mergeroads}
merged_mr = merge_roads(global_annual, c(3, 4, 5), keep = F) # keep = T keeps the original roads. 
names(merged_mr)
```


### Visualization

Visualize with tmap: convenient

```{r}
 
locations_sf = st_as_sf(merged_mr, coords = c("long","lat"))
osm_valuemean = tm_shape(locations_sf) +
  tm_dots( "value_mean", col = "value_mean", size = 0.05,title = "NO2 value",
     popup.vars = c("value_mean" )) + tm_view(basemaps = c('OpenStreetMap'))
#+tm_shape(lnd)+tm_lines()
tmap_save(osm_valuemean, "NO2mean.html")

```

```{r eval=F}
climatemissing= merged_mr%>%filter(is.na(wind_speed_10m_10))
locations_sf = st_as_sf(climatemissing, coords = c("long","lat"))
osm_valuemean = tm_shape(locations_sf) +
  tm_dots( "value_mean", col = "value_mean", size = 0.05,title = "NO2 value",
     popup.vars = c("value_mean" )) + tm_view(basemaps = c('OpenStreetMap'))
#+tm_shape(lnd)+tm_lines()
tmap_save(osm_valuemean, "climatemissing.html")
```

Visualize with leaflet: more control.
show Day/night ratio, red: day/night >1, blue, day/nigh <1 

```{r eval=F}
merged_fp = merged_mr %>% mutate(ratiodn = day_value/night_value) %>% mutate(color = ifelse(ratiodn > 1, "red", "blue"))
m  = leaflet(merged_fp) %>%
     addTiles() %>% addCircleMarkers(radius = ~value_mean/5, color = ~color, popup =   ~as.character(value_mean),fill = FALSE) %>% addProviderTiles(providers$Esri.NatGeoWorldMap) %>% addMouseCoordinates() %>%  
addHomeButton(ext = extent(116.2, 117, 39.7, 40), layer.name = "Beijing") %>% addHomeButton(ext = extent(5, 5.2, 52, 52.2), layer.name = "Utrecht")
saveWidget(m, file = "NO2daynight.html")
```

Boxplot

```{r}
countryname = paste(merged_mr$country, countrycode(merged_mr$country, 'iso2c', 'country.name'), sep = ":") 

#tag country with ppm 
# use the median for colour
mergedmedian = merged_mr %>% group_by(country) %>% mutate(median =  median(value_mean, na.rm = TRUE)) 
nrow(merged_mr)
merged_mr = merged_mr %>% group_by(country) %>% mutate(count1 = n())
 
countryname_s_e=ifelse( merged_mr$country %in% countrywithppm[countrywithppm %in% merged_mr$country], paste(countryname, "*", sep = ""), countryname)

mergedmedian$countryfullname = paste0(countryname_s_e," (",merged_mr$count1 ,")")

bp2 <- ggplot(mergedmedian, aes(x=countryfullname, y=value_mean, group=country)) +
  labs(x = "Country", y = expression(paste("NO"[2], "  ", mu, "g/", "m"^3)), cex = 1.5) +
  geom_boxplot(aes(fill = median)) + 
  theme(text = element_text(size = 13), axis.text.x = element_text(angle = 90, hjust = 1)) +   scale_fill_distiller(palette = "Spectral")
#   scale_color_brewer(direction = 1)
 
print(bp2 + ylim(0, 100))
#ggsave("boxplot.png")
```
 
Plot the paired correlation, for  road predictors, population, Tropomi. Compare the correlation graphs between Germnany and world. The correlation between NO2 concentration and predictor variables are much lower, calling for a non-linear method to model the hetrogeneities between countries. 
 
```{r}
merged_mr %>% na.omit %>% filter(country == "DE") %>%  ungroup() %>%dplyr::select(matches("value_mean|road_|night|trop")) %>% cor %>% corrplot(type = "upper", method = "pie", tl.cex = 0.7)
#merged_mr %>% na.omit %>% filter(country == "US") %>%  ungroup() %>%dplyr::select(matches("value_mean|road_|night|trop")) %>% cor %>% corrplot(type = "upper", method = "pie", tl.cex = 0.7)
#merged_mr %>% na.omit %>% filter(country == "CA") %>%  ungroup() %>%dplyr::select(matches("value_mean|road_|night|trop")) %>% cor %>% corrplot(type = "upper", method = "pie", tl.cex = 0.7)
#merged_mr %>% na.omit %>% filter(country == "CN") %>%  ungroup() %>%dplyr::select(matches("value_mean|road_|night|trop")) %>% cor %>% corrplot(type = "upper", method = "pie", tl.cex = 0.7)

merged_mr %>% na.omit  %>%  ungroup() %>%dplyr::select(matches("value_mean|road_|night|trop")) %>% cor %>% corrplot(type = "upper", method = "pie", tl.cex = 0.7) 
```


Inspecting spatial dependency using the variogram, assuming cutoff is 1 degree (111 km at nadir).
```{r}
grd_sp <- as_Spatial(locations_sf)
 
dt.vgm = variogram(value_mean~1, grd_sp, cutoff=   1)
plot(dt.vgm)

#Moran I test
#install.packages("ape", dependencies = TRUE)
#library(ape)

#merged_mrf =  merged_mr%>%filter(country == "US")
#no2.dists <- as.matrix(dist(cbind(merged_mrf$LONGITUDE, merged_mrf$LATITUDE)))
#no2.dists[1:5, 1:5]
#no2.inv <- 1/no2.dists
#diag(no2.inv) <- 0
#no2.inv[1:5, 1:5]
#Moran.I(merged_mrf$value_mean, na.rm = T, no2.inv) 
```

Inspecting spatial correlation within countries.
```{r countryvario}
countryvariogram = function(COUN, cutoff){
loca =  locations_sf%>%filter(country == COUN)
grd_sp <- as_Spatial(loca)
dt.vgm = variogram(value_mean~1, grd_sp, cutoff = cutoff)
plot(dt.vgm)
}
```

```{r}
countryvariogram("DE", 1)
countryvariogram("US", 1)
countryvariogram("CN", 1) # reason?
```

For the illustration purpose,  we simply remove missing data, there are not many, 41. In practice, careful handling is needed to choose between removing missing data, imputation or handle them explicitly in the model. 

```{r}
inde_var = merged_mr %>%na.omit() # 70 variables
```

#### Scatterplot
The scatter plots between predictors and mean NO2, Germany and global datasets. 
loess: moving regression, non-parametric, each smoothed value is given by a weighted linear least squares regression over the span.

```{r scatterplot}
inde_var %>% filter(country=="DE")%>%ungroup%>% dplyr::select(matches("road_class_M345|nightlight|temperature_2m_7|value")) %>% scatterplot(y_name = "value_mean", fittingmethod = "loess")
inde_var %>% filter(country=="DE")%>%ungroup%>% dplyr::select(matches("road_class_2|value")) %>% scatterplot(y_name = "value_mean", fittingmethod = "gam")

inde_var %>%ungroup%>% dplyr::select(matches("road_class_M345|nightlight|temperature_2m_7|value")) %>% scatterplot(y_name = "value_mean", fittingmethod = "loess")
inde_var %>% ungroup%>%  dplyr::select(matches("road_class_2|value")) %>% scatterplot(y_name = "value_mean", fittingmethod = "loess")
inde_var %>% ungroup%>% dplyr::select(matches("road_class_1|value")) %>% scatterplot(y_name = "value_mean", fittingmethod = "gam")

#inde_var %>% dplyr::select(matches("Tro|OMI|Rsp|night_value")) %>% scatterplot(y_name = "night_value", fittingmethod = "loess")
# why?

# can choose any variable to look at the scatterplot

#inde_var %>% dplyr::select(matches("ROAD_1|day_value")) %>% scatterplot(y_name = "day_value", fittingmethod = "gam")
```
Discussion 1, try different scatterplot and discuss about the findings
 

### Modelling
* Random Forest, 
* Gradient boosting machine, 
* XGboost

If we use a single regression tree, the tree and prediction error will be different if shuffeling training and testing data. To reduce the variance, a method called "bagging" is developed, which agregate over (weak) voters. If the predictor variables are correlated, the reduction in variance is decreasing, Random Forest comes to resecue by ramdomly sampling variables.

XGBoost is surely popular, as it won the Kaggle (machine learning prediction) competition. It has a few features such as being scalable, but most importantly, it super-imposed a regularization to prevent model over-fitting. However, in my experience, though I often obtain the lowest RMSE or highest R2 with XGBoost, the spatial pattern it predicts look a lot worse than random forest, or simpler linear model with regularization -- Lasso. It looks to predict lots of artefacts. We further compared various model  prediction results with mobile sensor measurements (with a typical Dutch transporting tool "bakfiets", which is a cargo-bike), and found XGBoost matches the least with the mobile sensor measurements! -- No matter how I tune the model.       

```{r}
inde_var = inde_var%>%ungroup()%>%dplyr::select(-country)
```

#### Hyperparameter tuning using R Caret package.

* Here I only show how to tune hyper-parameters, detailed description and what hyper-parameter I tunned are in "Glo_hyp_tun.Rmb"
* It is commonly (and strongly) recommended in deep learning to split the data into 3: model training; hyperparameter optimization; testing. The reason, is that the hyper-parameter optimization process may cause information leakage. However, separating a test dataset out may cause more severe bias. Actually, this question haunted me for a very long time since I started pulling out my results, and alsogenerated heated discussions between me and a reviewer of my recent global mapping paper. To reflect, [I wrote a discussion about this] (https://tomatofox.wordpress.com/2020/04/20/how-to-assess-accuracy-of-a-machine-learning-method-when-observations-are-limited/), comments appreciated!   

Let's come back to the model tunning, here I am showing to do this with the R package Caret, there are other packages,such as mlr3, but but Caret seems to be well-maintained, and is sufficient in most cases, and you can simply use ggplot on the caret::train object. All we need is to custom a tunning grid for tunning and control the resampling method.

Firstly, Random Forest, the most important hyperparameter are mtry - the number of variables sampled at each split, and min.node.size - the minimum number of observations at the leaf. The number of trees is also a hyperparameter, but it can be set as high as you like, as it will not cause model over-fitting as each tree is grown independently, which is different from boosting, which grows trees subsequently. Of course, you can also tune it.   

[Try after the workshop as it takes quite a while; set the "eval =T"]

```{r TuneRF, eval=F}
trl <- trainControl(method = "cv", number = 3) # control the resampling method
 tgrid <- expand.grid(
  .mtry = seq(7, 30, by = 3),
  .splitrule = "variance",
  .min.node.size = c(5, 10)
)
caret::train(value_mean ~ ., data =  inde_var , method='ranger', trControl  = trl, tuneGrid= tgrid) %>%ggplot()
#The final values used for the model were mtry = 25, splitrule = variance and min.node.size = 5.
```

In the same way, we can tune GBM [ Try after the workshop as it takes quite a while].

* Note: we can use "bernoulli" for binary data and "gaussian" for continuous. 

```{r TuneGBM, eval=F, include=FALSE}
gbmGrid <- expand.grid(interaction.depth=c(4, 5, 6), n.trees = ( 5:8)*150,
                         shrinkage=c( 0.05, 0.03, 0.01 ),
                         n.minobsinnode=c(5 ))
 
gbm.caret <- caret::train(value_mean~ ., data= inde_var,  method="gbm",
                   trControl=trainControl, 
                   tuneGrid=gbmGrid,  bag.fraction=0.6)
ggplot(gbm.caret)
```
 
Tunning XGBoost is more complex as it has a lot more hyperparameters to tune:
https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/

*1* gamma[default=0][range: (0,Inf)]
It controls regularization (or prevents overfitting). The optimal value of gamma depends on the data set and other parameter values. Higher the value, higher the regularization. Regularization means penalizing large coefficients which don't improve the model's performance. default = 0 means no regularization.
Tune trick: Start with 0 and check CV error rate. If you see train error >> test error, bring gamma into action.  

*2*. lambda and Alpha: similar to the Lasso Lambda, control the strength of regularization

*3*. nrounds[default=100]
It controls the maximum number of iterations. For classification, it is similar to the number of trees to grow.
Should be tuned using CV

*4*. eta[default=0.3][range: (0,1)]
It controls the learning rate, i.e., the rate at which our model learns patterns in data. After every round, it shrinks the feature weights to reach the best optimum.
Lower eta leads to slower computation. It must be supported by increase in nrounds.
Typically, it lies between 0.01 - 0.3

*5*. max_depth[default=6][range: (0,Inf)]
It controls the depth of the tree.
Larger data sets require deep trees to learn the rules from data.
Should be tuned using CV

```{r TuneXGBOOST, eval=F}
xgboostgrid = expand.grid(nrounds = seq(300, 2000, by = 50), max_depth = 3:5, eta = seq(0.05, 0.2, by = 0.05),gamma =  1,
colsample_bytree = 1,
min_child_weight = 1,
subsample = 0.7) 
trainControl <- trainControl(method="cv", number=5, savePredictions = "final", allowParallel = T) #5 - folds
# train the model
train(value_mean~., data=inde_var, method="xgbTree", trControl=trainControl, tuneGrid =xgboostgrid)%>%ggplot()
 
```

#### Models

###### Regression tree

If you train a single train, e can see the tree is stochastic. But we can look at the tree structure to get some intuition of the model structure.

```{r eval = F}
for (i in 2:5)
{
  set.seed(i)
  ctree_LUR(inde_var, y_varname= c("value_mean"), training = training, test =  test, grepstring = vastring)
}
```
 
###### Random Forest

Creates diverse set of trees because
1) trees are unstable w.r.t. changes in learning/training data (bagging)
2) randomly preselect mtry splitting variables in each split  

```{r}
ranger(value_mean~., data = inde_var)
```

#### Gradient boosting

Here I am showing the "gbm" package. The "dismo" package extends "gbm" with the deviviance calculated from a distribution that can be chosen by users. Note though the dismo is built on gbm functions, the hyperparameters are slightly different. 

```{r gradientboostingtree} 
gbm1 =  gbm(formula = value_mean~., data =inde_var, distribution = "gaussian", n.trees = 2000,
  interaction.depth = 6, shrinkage = 0.01, bag.fraction = 0.5 )
gbm1
summary(gbm1)
plot(gbm1, i.var = 2:3)
#plot(gbm1, i.var = 1) 
#rf_residual <- pre_rf -  rdf_test$NO2
```

##### Xgboost
```{r}
 y_varname= "value_mean"
  x = inde_var%>%dplyr::select(-value_mean)
  df_x = data.table(inde_var, keep.rownames = F)
  df_y =  inde_var$value_mean 
  formu = as.formula(paste(y_varname, "~.", sep = ""))
  dfmatrix_x = sparse.model.matrix(formu, data = df_x)[, -1]
  train_b = xgb.DMatrix(data = dfmatrix_x, label = df_y) 
  
  max_depth = 4
  eta = 0.01
  nthread = 4
  nrounds = 800
  Gamma = 2
  
  bst <- xgboost(data = train_b, max_depth = max_depth, eta = eta, nthread = nthread, nrounds = nrounds, Gamma = Gamma, verbose = 1, print_every_n = 200, early_stopping_rounds = 50, maximize = F )
 
```
 
 
##### Emsemble multiple models
caretEnsemble is computational intensive. Can customize using the "emsemble.R"

```{r ensemble, eval=FALSE}
#install.packages("caretEnsemble")
#library(caretEnsemble)

# Stacking Algorithms - Run multiple algos in one call.
#trainControl <- trainControl(method = "repeatedcv", 
#                             number = 10, 
#                             repeats = 2,
#                             savePredictions = TRUE, 
#                             classProbs = TRUE)

#algorithmList <- c('rf', 'adaboost', 'earth', 'xgbDART', 'svmRadial')

#set.seed(100)
#models <- caretList(value_mean ~ ., data = inde_var , trControl = trainControl, methodList = algorithmList) 
#results <- resamples(models)
#summary(results)
```
 
#### Important variables and Partial dependence plots 

Variable importance and partial dependence plots are commonly used to interpret models. 
```{r varimp}
pre_mat = subset_grep(inde_var , grepstring = paste0("value_mean|",vastring))
rf = ranger(value_mean~ ., data = na.omit( pre_mat), mtry = 25, num.trees = 1000, importance = "permutation")
rf
# ranger method
sort(importance(rf), decreasing = T)
```

[Try after workshop as it takes a while: Variable importance and partial dependence plots can be calculated and presented using vi and sparklines packages, which include more matrices and presentation functionalities. ] 
 
```{r vi, eval=F}
set.seed(2)
vip::list_metrics()

DF_P_r2 = vi(rf, method = "permute", target = "value_mean", metric = "r2" ) # very clear what method is used and what is the target
DF_P_rmse = vi(rf, method = "permute", target = "value_mean", metric = "rmse") 
vip (DF_P_r2)
vip (DF_P_rmse) 
a=add_sparklines(DF_P_r2, fit = rf)
saveWidget(a, file="sparkline.html")
```

 
Use a subset of variables in RF to inspect partial denpendence.

```{r}
pre_mat_s = inde_var%>%na.omit%>%ungroup() %>% dplyr::select(value_mean, road_class_2_50, nightlight_500, population_5000, road_class_M345_1000) 
lm_s = lm(value_mean~., data = pre_mat_s)
rf_s = ranger(value_mean~ ., data = pre_mat_s, num.trees = 1000, importance = "permutation")
rf_s
```
Partial dependence is the marginal effect one or two features have on the predicted outcome of a machine learning model. It is the integration of all the other predictors given each value of the variable under inspection. 
Partial dependence plot is calculated based on the assumption that the correlation between the variable to be inspected and variables to be integrated to be low. For example, if we are interested in the effect of population within 1000 m buffer, but we integrate over population within 3000 m buffer, then high population region as is shown with the 1000 m buffer data may include very low popolation within 3000 m buffer, which is very unlikely.   

```{r}
pre_mat_predictor = pre_mat_s%>%dplyr::select(-value_mean) 
ggpairs(pre_mat_predictor)
```

The partial dependence plots of linear and random forest regression

```{r pdplmrf}
p_lm = partial(lm_s, "road_class_M345_1000",plot = TRUE, rug = TRUE)
plot(p_lm) # Linear regression

p2 = partial(rf_s, "road_class_M345_1000",plot = TRUE, rug = TRUE)
plot(p2) # random forest
```

We can also inspect 2D and 3-D PDP plots for more in-depth insights of the joint effects from variables. [Try afterwork shop as it will take a wile]

```{r, eval=F}
#slow
pd <- partial(rf_s, pred.var = c("population_3000", "road_class_M345_1000"  ))

# Default PDP
pd1 = plotPartial(pd)

# Add contour lines and use a different color palette
rwb <- colorRampPalette(c("red", "white", "blue"))
pdp2 = plotPartial(pd, contour = TRUE, col.regions = rwb)
 
#3-D surface
 pdp3 <- plotPartial(pd, levelplot = F, zlab = "road_class_2_50", colorkey = T, 
                   screen = list(z = -20, x = -60) )

p3 = partial(rf_s, "road_class_2_50", plot = TRUE, rug = TRUE)
p1 = partial(rf_s, "population_3000", plot = TRUE, rug = TRUE)
grid.arrange(p1, p2, p3, pd1, pdp2, ncol = 2)

```

###### Mixed effect models

Though we used multiple "background variables" (e.g. climate, population) trying to discover hirarchical relationships, the models introduced above does not explicitly model the hirarchical relationships (e.g road effects within a country). For example, the NO2-road density relationships may be heterogenous between countries due to different emission regulations, fuel standards (e.g. Brazil use biof-fuels), as well as the sampling scheme (the geographically distribution) of air monitoring stations. Mixed-effect models (ME) have been developed specificaly to model hirarchical relationships -- data are clustred within higher level clusters. ME can be seen as a special case of Bayetian Hirarchical models.   

The variables are scaled (mean 0, std 1) so it will be easy for the model to find relationships.  

```{r}
set.seed(3)
merged_mr = merged_mr%>%drop_na()
smp_size <- floor(0.8* nrow(merged_mr))
training<- sample(seq_len(nrow(merged_mr)), size = smp_size)
test = seq_len(nrow(merged_mr))[-training] 
 
mpre =subset_grep(merged_mr, vastring)
scaled1 = data.frame(apply(mpre, 2, scale))
scaled1$value_mean = merged_mr$value_mean
```

Let's get some categorical variables for exploration. One is country, the other are two categorical variables constructed from continuous variabels TROPOMI and Night Light.

```{r}
scaled1$country =   merged_mr$country 

scaled1$tropofac = as.factor(cut(merged_mr$trop_mean_filt, seq(min(merged_mr$trop_mean_filt), max(merged_mr$trop_mean_filt), 100), label = c(1:(length(seq(min(merged_mr$trop_mean_filt), max(merged_mr$trop_mean_filt), 100))-1))))
 
scaled1$nifac = as.factor(cut(merged_mr$nightlight_5000, c( -0.001, 10, 30, 60,   max(merged_mr$nightlight_5000)), label = c(1:(length(sep)-1))))
```


The two figures below shows the relationship between NO2 and close-by primary road density, as well as nightlight is quite different between countries (first figure). The same applies for the relationships between station measured NO2 concentration and Tropomi NO2 column density.  

```{r}
scaled2 = scaled1 %>% filter(country %in% c("CN","ES","US","DE"))%>%
  ggplot( aes(x =road_class_2_50, y = value_mean, color = nifac)) +
  geom_point() + facet_wrap( ~ country)+ylab("NO2")+ labs(color='Night Light (category)') 
 suppressWarnings(print(scaled2))
 #ggsave("r50ni_4cou.png")
 
 scaled2 = scaled1 %>% filter(country %in% c("CN","ES","US","DE"))%>%
  ggplot( aes(x = trop_mean_filt, y = value_mean)) +
  geom_point() + facet_wrap( ~ country)+
  geom_smooth(method = "loess") +ylab("NO2")
 suppressWarnings(print(scaled2))
# ggsave("pop4cou.png")
```

Mixed effect model vs. Linear model with categories as variables. The mixed effect model with intersection being the random effect is similar to standard linear regression model with each category as a variable. 

```{r}
#select a few important variables
scaled_sel = scaled1%>%select(population_5000 ,road_class_M345_1000 , road_class_M345_50 , road_class_2_100 ,road_class_2_25 , trop_mean_filt , nightlight_500 ,road_class_2_50, country, value_mean)

scaledtrain = scaled_sel[training,]
scaledtest = scaled_sel[test,] 

#lme model vs. lm 
me = lmer(value_mean ~ population_5000 +road_class_M345_1000 + road_class_M345_50 + road_class_2_100 + road_class_2_25 + trop_mean_filt + nightlight_500 +road_class_2_50+(1| country), scaledtrain)

fixe = lm(value_mean ~ population_5000 +road_class_M345_1000 + road_class_M345_50 + road_class_2_100 + road_class_2_25 + trop_mean_filt + nightlight_500 +road_class_2_50+country, scaledtrain)
 
pre_me1= predict(me, scaledtest)
pre_fixe= predict(fixe, scaledtest)
 
error_matrix(scaledtest$value_mean,prediction = pre_me1) # mixed effect
error_matrix(scaledtest$value_mean,prediction = pre_fixe)
```

This time we let the road density within a 50 meter buffer be the random variable. We see a small increase in accuracy. But 
```{r}
me2 = lmer(value_mean ~ population_5000 +road_class_M345_1000 + road_class_M345_50 + road_class_2_100 + road_class_2_25 + trop_mean_filt + nightlight_500 +road_class_2_50+(road_class_2_50| country), scaledtrain)
me2
pre_me2= predict(me2, scaledtest)

error_matrix(scaledtest$value_mean,prediction = pre_me2) # mixed effect

#rfpre= predict(ranger(value_mean~., data =scaled_sel),scaledtest)%>%predictions()
#error_matrix(scaledtest$value_mean,prediction = rfpre)

``` 

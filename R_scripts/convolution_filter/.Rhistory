length(yvar)
knitr::opts_chunk$set(fig.width=12, fig.height=8, fig.path=paste0('hyperparametertunning',  "/"),
echo=T, warning=FALSE, message=FALSE, dev = "pdf")
ipak <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
if (length(new.pkg))
install.packages(new.pkg, dependencies = TRUE , repos='http://cran.muenster.r-project.org')
sapply(pkg, require, character.only = TRUE)
}
packages <- c( "dplyr",  "devtools", "ranger", "gbm","xgboost", "data.table", "vcd","Matrix","mlr3","tmap", "sf","spgwr", "ggplot2", "ggtheme","tidyr","tmap", "gstat", "caret")
ipak(packages)
#install_github("mengluchu/APMtools")
library(APMtools)
data("global_annual")
y_var = "value_mean"
prestring =  "road|nightlight|population|temp|wind|trop|indu|elev"
varstring = paste(prestring,y_var,sep="|")
merged = global_annual  %>%   merge_roads( c(3, 4, 5), keep = F) %>%na.omit() %>%
ungroup()%>%dplyr::select(matches(varstring))
#install.packages("caret")
#library(caret)
xgboostgrid = expand.grid(nrounds = seq(300, 2000, by = 50), max_depth = 3:5, eta = seq(0.05, 0.2, by = 0.05),gamma =  1, lambda = seq(0.05, 0.4, by = 0.05),
colsample_bytree = 1,
min_child_weight = 1,
subsample = 0.7)
#gamma: Minimum loss reduction required to make a further partition on a leaf node of the tree. The larger gamma is, the more conservative the algorithm will be.
trainControl <- trainControl(method="cv", number=5, savePredictions = "final", allowParallel = T) #5 - folds
# train the model
model <- train(value_mean~., data=merged, method="xgbTree", trControl=trainControl, tuneGrid =xgboostgrid)
ipak <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
if (length(new.pkg))
install.packages(new.pkg, dependencies = TRUE, repos='http://cran.muenster.r-project.org')
sapply(pkg, require, character.only = TRUE)
}
packages <- c( "raster
ipak <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
if (length(new.pkg))
install.packages(new.pkg, dependencies = TRUE, repos='http://cran.muenster.r-project.org')
sapply(pkg, require, character.only = TRUE)
}
packages <- c( "raster", "dplyr", "devtools", "rgdal","Matrix","xgboost", "data.table" , "randomForest", "glmnet" ,"rasterVis" ,"RcolorBrew"  )
ipak(packages)
xgb2= raster("~/Downloads/xgbph_slowlr.tif")
library(rasterVis)
myTheme = rasterTheme(region = rev(brewer.pal(7, "Spectral")))
#quantile(global_annual$value_mean, c(0.01, 0.999, 0.99999))
#quite clear LAsso is not robust against exterme values. Question is do we need to remove very high values, like larger than 200, before aggregation? the maximum is 98 for the meanIt's going to be 62 for 99% and 84 for 99.9%
levelplot(xgb1, at =seq(10,100, by =3) , par.settings = myTheme)
#quantile(global_annual$value_mean, c(0.01, 0.999, 0.99999))
#quite clear LAsso is not robust against exterme values. Question is do we need to remove very high values, like larger than 200, before aggregation? the maximum is 98 for the meanIt's going to be 62 for 99% and 84 for 99.9%
levelplot(xgb2, at =seq(10,100, by =3) , par.settings = myTheme)
#quantile(global_annual$value_mean, c(0.01, 0.999, 0.99999))
#quite clear LAsso is not robust against exterme values. Question is do we need to remove very high values, like larger than 200, before aggregation? the maximum is 98 for the meanIt's going to be 62 for 99% and 84 for 99.9%
levelplot(xgb2,   par.settings = myTheme)
myTheme = rasterTheme(region = rev(brewer.pal(7, "Spectral")))
#quantile(global_annual$value_mean, c(0.01, 0.999, 0.99999))
#quite clear LAsso is not robust against exterme values. Question is do we need to remove very high values, like larger than 200, before aggregation? the maximum is 98 for the meanIt's going to be 62 for 99% and 84 for 99.9%
levelplot(xgb2,   par.settings = myTheme)
myTheme = rasterTheme(region = rev(brewer.pal(7, "Spectral")))
library(RColorBrewer)
myTheme = rasterTheme(region = rev(brewer.pal(7, "Spectral")))
levelplot(la1, par.settings = myTheme) #
#quantile(global_annual$value_mean, c(0.01, 0.999, 0.99999))
#quite clear LAsso is not robust against exterme values. Question is do we need to remove very high values, like larger than 200, before aggregation? the maximum is 98 for the meanIt's going to be 62 for 99% and 84 for 99.9%
levelplot(xgb2,   par.settings = myTheme)
###########################################################################
# visualize
###############################################################
rf1= raster("~/Downloads/non_backups/rfmph.tif")
rf1 = projectRaster(rf1, crs=   CRS("+init=epsg:4326"))
xgb2 = projectRaster(xgb2, crs=   CRS("+init=epsg:4326"))
getwd()
locations_sf = st_as_sf(global_annual, coords = c("long","lat"))
osm_valuemean = tm_shape(rf1)+
tm_raster(names(rf1),palette = "-Spectral", n = 9,alpha = 0.9)+
tm_shape(xgb2)+
tm_raster(names(xgb2),palette = "-Spectral", n = 9,alpha = 0.9)+
tm_shape(locations_sf)+
tm_dots( "value_mean", col = "value_mean", size = 0.05,title = "NO2 value",
popup.vars = c("value_mean" ))+
tm_view(basemaps = c('OpenStreetMap'))
tmap_save(osm_valuemean, "/Users/menglu/Documents/GitHub/Global mapping/rfxgb_phe.html")
xgb3= raster("~/Downloads/lr003lam002.tif")
xgb3 = projectRaster(xgb3, crs=   CRS("+init=epsg:4326"))
locations_sf = st_as_sf(global_annual, coords = c("long","lat"))
osm_valuemean = tm_shape(rf1)+
tm_raster(names(rf1),palette = "-Spectral", n = 9,alpha = 0.9)+
tm_shape(xgb2)+
tm_raster(names(xgb2),palette = "-Spectral", n = 9,alpha = 0.9)+
tm_shape(xgb3)+
tm_raster(names(xgb3),palette = "-Spectral", n = 9,alpha = 0.9)+
tm_shape(locations_sf)+
tm_dots( "value_mean", col = "value_mean", size = 0.05,title = "NO2 value",
popup.vars = c("value_mean" ))+
tm_view(basemaps = c('OpenStreetMap'))
tmap_save(osm_valuemean, "/Users/menglu/Documents/GitHub/Global mapping/rfxgb_phe.html")
ipak <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
if (length(new.pkg))
install.packages(new.pkg, dependencies = TRUE , repos='http://cran.muenster.r-project.org')
sapply(pkg, require, character.only = TRUE)
}
packages <- c( "devtools", "dplyr","data.table" , "ggplot2" , "RColorBrewer", "raster", "rasterVis", "rgdal","Matrix","xgboost",  "glmnet", "ranger", "randomForest"
,"tidyverse" ,"stargazer")
ipak(packages)
install_github("mengluchu/APMtools")
library(APMtools)
data(global_annual)
install_github("mengluchu/APMtools")
knitr::opts_chunk$set(fig.width=12, fig.height=8, fig.path=paste0('global_crossvali',"/"),
echo=F, warning=FALSE, message=FALSE, dev = "png", include = T)
ipak <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
if (length(new.pkg))
install.packages(new.pkg, dependencies = TRUE , repos='http://cran.muenster.r-project.org')
sapply(pkg, require, character.only = TRUE)
}
packages <- c( "devtools", "dplyr","data.table" , "ggplot2" , "RColorBrewer", "raster", "rasterVis", "rgdal","Matrix","xgboost",  "glmnet", "ranger", "randomForest"
,"tidyverse" ,"stargazer")
ipak(packages)
install_github("mengluchu/APMtools")
library(APMtools)
data(global_annual)
ipak <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
if (length(new.pkg))
install.packages(new.pkg, dependencies = TRUE , repos='http://cran.muenster.r-project.org')
sapply(pkg, require, character.only = TRUE)
}
packages <- c( "devtools", "dplyr","data.table" , "ggplot2" , "RColorBrewer", "raster", "rasterVis", "rgdal","Matrix","xgboost",  "glmnet", "ranger", "randomForest"
,"tidyverse" ,"stargazer")
ipak(packages)
install_github("mengluchu/APMtools")
library(APMtools)
data(global_annual)
y_var = "value_mean"
prestring =  "road|nightlight|population|temp|wind|trop|indu|elev"
varstring = paste(prestring,y_var,sep="|")
merged = global_annual  %>%   merge_roads( c(3, 4, 5), keep = F)  %>%
ungroup()%>%dplyr::select(matches(varstring))
merged_xgb= global_annual  %>%   merge_roads( c(3, 4, 5), keep = F)  %>%
ungroup()%>%dplyr::select(matches(varstring))
#V2= c("P_LM_NO_OMI_day","P_LM_with_OMI_day","P_LM_night","P_Lasso_day","P_lasso_night", "P_rf_day","P_rf_night","P_ctree_day")
#for ( i in 1:10)
crossvali =  function(n,df, y_var) {
smp_size <- floor(0.8 * nrow(df))
set.seed(n)
training<- sample(seq_len(nrow(df)), size = smp_size)
test = seq_len(nrow(df))[-training]
#P_rf = rf_LUR(df, numtrees =  1000, mtry = 34, vis1 = F,y_varname= y_var, training=training, test=test, grepstring =varstring)
#P_rf_la = rf_Lasso_LUR(df, numtrees =  1000, mtry = 34, vis1 = F,y_varname= y_var, training=training, test=test, grepstring =varstring)
P_xgb= xgboost_LUR(df, max_depth =5, gamma=1, eta =0.003, nthread = 32, xgblambda = 0.002, nrounds =1700, y_varname= y_var,training=training, test=test, grepstring =varstring)
#P_Lasso =  Lasso(df,alpha =1 , vis1  = F,y_varname = y_var,training=training, test=test,grepstring =prestring )
#V = cbind(P_xgb, P_rf, P_rf_la, P_Lasso)
}
V2 = lapply(1:2, df = merged_xgb, y_var = y_var,crossvali)
y_var
y_var
V2 = lapply(1:2, df = merged_xgb, _var = y_var,crossvali)
V2 = lapply(1:2, df = merged_xgb, y_var = y_var,crossvali)
xgboost_LUR
install_github("mengluchu/APMtools")
install_github("mengluchu/APMtools")
library(APMtools)
